---
output-file: longhorizon.html
title: Forecasting on a long horizon
---


[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nixtla/nixtla/blob/main/nbs/docs/tutorials/12_longhorizon.ipynb)

```python
from nixtlats import TimeGPT
```


```python
timegpt = TimeGPT(
    # defaults to os.environ.get("TIMEGPT_TOKEN")
    token = 'my_token_provided_by_nixtla'
)
```

Let’s load the ETTh1 dataset. This is a widely used dataset to evaluate
models on their long-horizon forecasting capabalities.

The ETTh1 dataset monitors an electricity transformer from a region of a
province of China including oil temperature and variants of load (such
as high useful load and high useless load) from July 2016 to July 2018
at an hourly frequency.

For this tutorial, let’s only consider the oil temperature variation
over time.

```python
from datasetsforecast.long_horizon import LongHorizon

Y_df, *_ = LongHorizon.load(directory='./', group='ETTh1')

Y_df.head()
```

|     | unique_id | ds                  | y        |
|-----|-----------|---------------------|----------|
| 0   | OT        | 2016-07-01 00:00:00 | 1.460552 |
| 1   | OT        | 2016-07-01 01:00:00 | 1.161527 |
| 2   | OT        | 2016-07-01 02:00:00 | 1.161527 |
| 3   | OT        | 2016-07-01 03:00:00 | 0.862611 |
| 4   | OT        | 2016-07-01 04:00:00 | 0.525227 |

For this small experiment, let’s set the horizon to 96 time steps (4
days into the future), and we will feed TimeGPT with a sequence of 42
days.

```python
test = Y_df[-96:]             # 96 = 4 days x 24h/day
input_seq = Y_df[-1104:-96]   # Gets a sequence of 1008 observations (1008 = 42 days * 24h/day)
```

Now, we are ready to use TimeGPT for long-horizon forecasting. Here, we
need to set the `model` parameter to `"timegpt-1-long-horizon"`. This is
the specialized model in TimeGPT that can handle such tasks.

```python
fcst_df = timegpt.forecast(
    df=input_seq,
    h=96,
    level=[90],
    finetune_steps=10,
    finetune_loss='mae',
    model='timegpt-1-long-horizon',
    time_col='ds',
    target_col='y'
)
```

``` text
INFO:nixtlats.timegpt:Validating inputs...
INFO:nixtlats.timegpt:Preprocessing dataframes...
INFO:nixtlats.timegpt:Inferred freq: H
INFO:nixtlats.timegpt:Calling Forecast Endpoint...
```

```python
timegpt.plot(Y_df[-168:], fcst_df, models=['TimeGPT'], level=[90], time_col='ds', target_col='y')
```

![](/nixtla/docs/tutorials/12_longhorizon_files/figure-markdown_strict/cell-8-output-1.png)

Let’s now evaluate the performance of TimeGPT using the mean absolute
error (MAE).

```python
test = test.copy()

test.loc[:, 'TimeGPT'] = fcst_df['TimeGPT'].values
```


```python
from utilsforecast.losses import mae

evaluation = mae(test, models=['TimeGPT'], id_col='unique_id', target_col='y')

print(evaluation)
```

``` text
  unique_id   TimeGPT
0        OT  0.146111
```

Here, TimeGPT achieves a MAE of 0.14.

