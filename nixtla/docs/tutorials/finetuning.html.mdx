---
output-file: finetuning.html
title: Finetuning

---

Fine-tuning is a powerful process for utilizing TimeGPT more
effectively. Foundation models are pre-trained on vast amounts of data,
capturing wide-ranging features and patterns. These models can then be
specialized for specific contexts or domains. With fine-tuning, the
model’s parameters are refined to forecast a new task, allowing it to
tailor its vast pre-existing knowledge toward the requirements of the
new data. Fine-tuning thus serves as a crucial bridge, linking TimeGPT’s
broad capabilities to your tasks specificities.

Concretely, the process of fine-tuning consists of performing a certain
number of training iterations on your input data minimizing the
forecasting error. The forecasts will then be produced with the updated
model. To control the number of iterations, use the `finetune_steps`
argument of the `forecast` method.

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nixtla/nixtla/blob/main/nbs/docs/tutorials/5_finetuning.ipynb)

```python
import pandas as pd
from nixtlats import TimeGPT
```

``` text
/home/ubuntu/miniconda/envs/nixtlats/lib/python3.11/site-packages/statsforecast/core.py:25: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from tqdm.autonotebook import tqdm
```

```python
timegpt = TimeGPT(
    # defaults to os.environ.get("TIMEGPT_TOKEN")
    token = 'my_token_provided_by_nixtla'
)
```

Here’s an example of how to fine-tune TimeGPT:

```python
df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')
df.head()
```

|     | timestamp  | value |
|-----|------------|-------|
| 0   | 1949-01-01 | 112   |
| 1   | 1949-02-01 | 118   |
| 2   | 1949-03-01 | 132   |
| 3   | 1949-04-01 | 129   |
| 4   | 1949-05-01 | 121   |

```python
timegpt_fcst_finetune_df = timegpt.forecast(
    df=df, h=12, finetune_steps=10,
    time_col='timestamp', target_col='value',
)
```

``` text
INFO:nixtlats.timegpt:Validating inputs...
INFO:nixtlats.timegpt:Preprocessing dataframes...
INFO:nixtlats.timegpt:Calling Forecast Endpoint...
```

```python
timegpt.plot(
    df, timegpt_fcst_finetune_df, 
    time_col='timestamp', target_col='value',
)
```

![](/nixtla/docs/tutorials/5_finetuning_files/figure-markdown_strict/cell-7-output-1.png)

In this code, `finetune_steps=10` means the model will go through 10
iterations of training on your time series data.

Keep in mind that fine-tuning can be a bit of trial and error. You might
need to adjust the number of `finetune_steps` based on your specific
needs and the complexity of your data. It’s recommended to monitor the
model’s performance during fine-tuning and adjust as needed. Be aware
that more `finetune_steps` may lead to longer training times and could
potentially lead to overfitting if not managed properly.

Remember, fine-tuning is a powerful feature, but it should be used
thoughtfully and carefully.

